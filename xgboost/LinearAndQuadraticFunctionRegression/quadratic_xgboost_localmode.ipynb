{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Quadratic Regression Dataset - Linear Regression vs XGBoost</h2>\n",
    "\n",
    "Model is trained with XGBoost installed in notebook instance\n",
    "\n",
    "In the later examples, we will train using SageMaker's XGBoost algorithm.\n",
    "\n",
    "Training on SageMaker takes several minutes (even for simple dataset).  \n",
    "\n",
    "If algorithm is supported on Python, we will try them locally on notebook instance\n",
    "\n",
    "This allows us to quickly learn an algorithm, understand tuning options and then finally train on SageMaker Cloud\n",
    "\n",
    "In this exercise, let's compare XGBoost and Linear Regression for Quadratic regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install xgboost in notebook instance.\n",
    "#### Command to install xgboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# XGBoost \n",
    "import xgboost as xgb\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('quadratic_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.x,df.y,label='Target')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Input Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.title('Quadratic Regression Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'quadratic_train.csv'\n",
    "validation_file = 'quadratic_validation.csv'\n",
    "\n",
    "# Specify the column names as the file does not have column header\n",
    "df_train = pd.read_csv(train_file,names=['y','x'])\n",
    "df_validation = pd.read_csv(validation_file,names=['y','x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_train.x,df_train.y,label='Training',marker='.')\n",
    "plt.scatter(df_validation.x,df_validation.y,label='Validation',marker='.')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Input Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Quadratic Regression Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:,1:] # Features: 1st column onwards \n",
    "y_train = df_train.iloc[:,0].ravel() # Target: 0th column\n",
    "\n",
    "X_validation = df_validation.iloc[:,1:]\n",
    "y_validation = df_validation.iloc[:,0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of XGBoost Regressor\n",
    "# XGBoost Training Parameter Reference: \n",
    "#   https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "regressor = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train,y_train, eval_set = [(X_train, y_train), (X_validation, y_validation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = regressor.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rounds = range(len(eval_result['validation_0']['rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=training_rounds,y=eval_result['validation_0']['rmse'],label='Training Error')\n",
    "plt.scatter(x=training_rounds,y=eval_result['validation_1']['rmse'],label='Validation Error')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training Vs Validation Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(regressor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Dataset Compare Actual and Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regressor.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('XGBoost - Validation Dataset')\n",
    "plt.scatter(df_validation.x,df_validation.y,label='actual',marker='.')\n",
    "plt.scatter(df_validation.x,result,label='predicted',marker='.')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Metrics\n",
    "print('XGBoost Algorithm Metrics')\n",
    "mse = mean_squared_error(df_validation.y,result)\n",
    "print(\" Mean Squared Error: {0:.2f}\".format(mse))\n",
    "print(\" Root Mean Square Error: {0:.2f}\".format(mse**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual\n",
    "# Over prediction and Under Prediction needs to be balanced\n",
    "# Training Data Residuals\n",
    "residuals = df_validation.y - result\n",
    "plt.hist(residuals)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Actual - Predicted')\n",
    "plt.ylabel('Count')\n",
    "plt.title('XGBoost Residual')\n",
    "plt.axvline(color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of values greater than zero and less than zero\n",
    "value_counts = (residuals > 0).value_counts(sort=False)\n",
    "\n",
    "print(' Under Estimation: {0}'.format(value_counts[True]))\n",
    "print(' Over  Estimation: {0}'.format(value_counts[False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for entire dataset\n",
    "plt.plot(df.x,df.y,label='Target')\n",
    "plt.plot(df.x,regressor.predict(df[['x']]) ,label='Predicted')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Input Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.title('XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Weights assigned by Linear Regression.\n",
    "\n",
    "Original Function: 5*x**2 -23*x + 47 + some noise\n",
    "\n",
    "Linear Regression Function: -15.08 * x + 709.86 \n",
    "\n",
    "Linear Regression Coefficients and Intercepts are not close to actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lin_regressor.predict(df_validation[['x']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('LinearRegression - Validation Dataset')\n",
    "plt.scatter(df_validation.x,df_validation.y,label='actual',marker='.')\n",
    "plt.scatter(df_validation.x,result,label='predicted',marker='.')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Metrics\n",
    "print('Linear Regression Metrics')\n",
    "mse = mean_squared_error(df_validation.y,result)\n",
    "print(\" Mean Squared Error: {0:.2f}\".format(mse))\n",
    "print(\" Root Mean Square Error: {0:.2f}\".format(mse**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual\n",
    "# Over prediction and Under Prediction needs to be balanced\n",
    "# Training Data Residuals\n",
    "residuals = df_validation.y - result\n",
    "plt.hist(residuals)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Actual - Predicted')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Linear Regression Residual')\n",
    "plt.axvline(color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of values greater than zero and less than zero\n",
    "value_counts = (residuals > 0).value_counts(sort=False)\n",
    "\n",
    "print(' Under Estimation: {0}'.format(value_counts[True]))\n",
    "print(' Over  Estimation: {0}'.format(value_counts[False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for entire dataset\n",
    "plt.plot(df.x,df.y,label='Target')\n",
    "plt.plot(df.x,lin_regressor.predict(df[['x']]) ,label='Predicted')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Input Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.title('LinearRegression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is showing clear symptoms of under-fitting\n",
    "\n",
    "Input Features are not sufficient to capture complex relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Your Turn</h2>\n",
    "You can correct this under-fitting issue by adding relavant features.\n",
    "\n",
    "1. What feature will you add and why?\n",
    "2. Complete the code and Test\n",
    "3. What performance do you see now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column names as the file does not have column header\n",
    "df_train = pd.read_csv(train_file,names=['y','x'])\n",
    "df_validation = pd.read_csv(validation_file,names=['y','x'])\n",
    "df = pd.read_csv('quadratic_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new features "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place holder to add new features to df_train, df_validation and df\n",
    "if you need help, scroll down to see the answer\n",
    "Add your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your new features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:,1:] # Features: 1st column onwards \n",
    "y_train = df_train.iloc[:,0].ravel() # Target: 0th column\n",
    "\n",
    "X_validation = df_validation.iloc[:,1:]\n",
    "y_validation = df_validation.iloc[:,0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Function: -23*x + 5*x**2 + 47 + some noise (rewritten with x term first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lin_regressor.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('LinearRegression - Validation Dataset')\n",
    "plt.scatter(df_validation.x,df_validation.y,label='actual',marker='.')\n",
    "plt.scatter(df_validation.x,result,label='predicted',marker='.')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Metrics\n",
    "print('Linear Regression Metrics')\n",
    "mse = mean_squared_error(df_validation.y,result)\n",
    "print(\" Mean Squared Error: {0:.2f}\".format(mse))\n",
    "print(\" Root Mean Square Error: {0:.2f}\".format(mse**.5))\n",
    "\n",
    "print(\"***You should see an RMSE score of 30.45 or less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for entire dataset\n",
    "plt.plot(df.x,df.y,label='Target')\n",
    "plt.plot(df.x,lin_regressor.predict(df[['x','x2']]) ,label='Predicted')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Input Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.title('LinearRegression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for under-fitting\n",
    "\n",
    "add a new X**2 term to the dataframe\n",
    "\n",
    "syntax:\n",
    "\n",
    "df_train['x2'] = df_train['x']**2\n",
    "\n",
    "df_validation['x2'] = df_validation['x']**2\n",
    "\n",
    "df['x2'] = df['x']**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Based Algorithms have a lower bound and upper bound for predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Function\n",
    "def quad_func (x):\n",
    "    return 5*x**2 -23*x + 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is outside range of training samples\n",
    "# New Feature: Adding X^2 term\n",
    "\n",
    "X = np.array([-100,-25,25,1000,5000])\n",
    "y = quad_func(X)\n",
    "df_tmp = pd.DataFrame({'x':X,'y':y,'x2':X**2})\n",
    "df_tmp['xgboost']=regressor.predict(df_tmp[['x']])\n",
    "df_tmp['linear']=lin_regressor.predict(df_tmp[['x','x2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_tmp.x,df_tmp.y,label='Actual',color='r')\n",
    "plt.plot(df_tmp.x,df_tmp.linear,label='LinearRegression')\n",
    "plt.plot(df_tmp.x,df_tmp.xgboost,label='XGBoost')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Input Outside Range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is inside range of training samples\n",
    "X = np.array([-15,-12,-5,0,1,3,5,7,9,11,15,18])\n",
    "y = quad_func(X)\n",
    "df_tmp = pd.DataFrame({'x':X,'y':y,'x2':X**2})\n",
    "df_tmp['xgboost']=regressor.predict(df_tmp[['x']])\n",
    "df_tmp['linear']=lin_regressor.predict(df_tmp[['x','x2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Predictions have an upper bound and lower bound\n",
    "# Linear Regression Extrapolates\n",
    "plt.scatter(df_tmp.x,df_tmp.y,label='Actual',color='r')\n",
    "plt.plot(df_tmp.x,df_tmp.linear,label='LinearRegression')\n",
    "plt.plot(df_tmp.x,df_tmp.xgboost,label='XGBoost')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Input within range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Summary</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this exercise, we compared performance of XGBoost model and Linear Regression on a quadratic dataset\n",
    "2. The relationship between input feature and target was non-linear.\n",
    "3. XGBoost handled it pretty well; whereas, linear regression was under-fitting\n",
    "4. To correct the issue, we had to add additional features for linear regression\n",
    "5. With this change, linear regression performed much better\n",
    "\n",
    "XGBoost can detect patterns involving non-linear relationship; whereas, algorithms like linear regression may need complex feature engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
