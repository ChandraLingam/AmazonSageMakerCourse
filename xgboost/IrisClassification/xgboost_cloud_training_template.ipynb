{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Built-in Algorithm - Iris Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# SageMaker SDK Documentation: http://sagemaker.readthedocs.io/en/latest/estimators.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'chandra-ml-sagemaker'\n",
    "training_file_key = 'iris/iris_train.csv'\n",
    "validation_file_key = 'iris/iris_validation.csv'\n",
    "\n",
    "s3_model_output_location = r's3://{0}/iris/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{0}/{1}'.format(bucket_name,training_file_key)\n",
    "s3_validation_file_location = r's3://{0}/{1}'.format(bucket_name,validation_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3_model_output_location)\n",
    "print(s3_training_file_location)\n",
    "print(s3_validation_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and Reading from S3 is just as easy\n",
    "# files are referred as objects in S3.  \n",
    "# file name is referred as key name in S3\n",
    "# Files stored in S3 are automatically replicated across 3 different availability zones \n",
    "# in the region where the bucket was created.\n",
    "\n",
    "# http://boto3.readthedocs.io/en/latest/guide/s3.html\n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3('iris_train.csv',bucket_name,training_file_key)\n",
    "write_to_s3('iris_validation.csv',bucket_name,validation_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Algorithm Docker Image\n",
    "### AWS Maintains a separate image for every region and algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spot Instance - Save up to 90% of training cost by using spot instances when compared to on-demand instances\n",
    "# Reference: https://github.com/aws-samples/amazon-sagemaker-managed-spot-training/blob/main/xgboost_built_in_managed_spot_training_checkpointing/xgboost_built_in_managed_spot_training_checkpointing.ipynb\n",
    "\n",
    "# if you are still on two-month free-tier you can use the on-demand instance by setting:\n",
    "#   use_spot_instances = False\n",
    "\n",
    "# We will use spot for training\n",
    "use_spot_instances = True\n",
    "max_run = 3600 # in seconds\n",
    "max_wait = 7200 if use_spot_instances else None # in seconds\n",
    "\n",
    "job_name = 'xgboost-iris-v1'\n",
    "\n",
    "checkpoint_s3_uri = None\n",
    "\n",
    "if use_spot_instances:\n",
    "    checkpoint_s3_uri = f's3://{bucket_name}/iris/checkpoints/{job_name}'\n",
    "    \n",
    "print (f'Checkpoint uri: {checkpoint_s3_uri}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This role contains the permissions needed to train, deploy models\n",
    "# SageMaker Service is trusted to assume this role\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html#sagemaker.image_uris.retrieve\n",
    "\n",
    "# SDK 2 uses image_uris.retrieve the container image location\n",
    "\n",
    "# Use XGBoost 1.2 version \n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\",sess.boto_region_name,version=\"1.2-2\")\n",
    "\n",
    "print (f'Using XGBoost Container {container}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the training job\n",
    "# Specify type and number of instances to use\n",
    "# S3 location where final artifacts needs to be stored\n",
    "\n",
    "#   Reference: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "\n",
    "# for managed spot training, specify the use_spot_instances flag, max_run, max_wait and checkpoint_s3_uri\n",
    "\n",
    "# SDK 2.x version does not require train prefix for instance count and type\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=s3_model_output_location,\n",
    "    sagemaker_session=sess,\n",
    "    base_job_name = job_name,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyper parameters that appropriate for the training algorithm\n",
    "# XGBoost Training Parameter Reference: \n",
    "#   https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "estimator.set_hyperparameters(max_depth=5,\n",
    "                              objective=\"multi:softmax\",\n",
    "                              eval_metric=\"mlogloss\",\n",
    "                              num_class=3,\n",
    "                              num_round=100,\n",
    "                              early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Specify Training Data Location and Optionally, Validation Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content type can be libsvm or csv for XGBoost\n",
    "training_input_config = sagemaker.session.TrainingInput(\n",
    "    s3_data=s3_training_file_location,\n",
    "    content_type='csv',\n",
    "    s3_data_type='S3Prefix')\n",
    "\n",
    "validation_input_config = sagemaker.session.TrainingInput(\n",
    "    s3_data=s3_validation_file_location,\n",
    "    content_type='csv',\n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "data_channels = {'train': training_input_config, 'validation': validation_input_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_input_config.config)\n",
    "print(validation_input_config.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost supports \"train\", \"validation\" channels\n",
    "# Reference: Supported channels by algorithm\n",
    "#   https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "estimator.fit(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.m5.xlarge',\n",
    "                             endpoint_name = job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Run Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK 2.0 serializers\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict([[4.8,3.4,1.6,0.2],[4.8,3.4,1.6,0.2],[5.8,2.7,4.1,1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
